{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "284a3331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A Slope calculation (degrees)\u001b[39m\n",
      "C Horn, B.K.P., 1981. Hill shading and the reflectance map. Proceedings of the IEEE 69, 14–47. doi:10.1109/PROC.1981.11918\u001b[39m\n",
      "\n",
      "\u001b[2Kt Wall-time = 0.235133\u001b[39m======================= ] (99% - 0.0s - 1 threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed features:\n",
      "   latitude  longitude   frp       u10       v10   elevation      slope  \\\n",
      "0  33.81573 -118.23775  1.05  1.259857  3.371613    1.781858  69.389099   \n",
      "1  34.15556 -118.19301  1.56  0.662201  0.849152  434.277283  80.075356   \n",
      "2  34.29366 -118.80275  1.33  0.376068  0.480011  297.056061  56.920059   \n",
      "3  34.33566 -118.51929  1.25  0.539154  0.854034  581.089966  73.065117   \n",
      "4  34.42990 -118.64459  0.86  0.599701 -1.086395  350.062622  75.363266   \n",
      "\n",
      "  confidence  \n",
      "0          n  \n",
      "1          n  \n",
      "2          n  \n",
      "3          n  \n",
      "4          n  \n",
      "\n",
      "Total features: 1731\n",
      "NaN values:\n",
      "latitude      0\n",
      "longitude     0\n",
      "frp           0\n",
      "u10           0\n",
      "v10           0\n",
      "elevation     0\n",
      "slope         0\n",
      "confidence    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import richdem as rd\n",
    "from rasterio.transform import rowcol\n",
    "from datetime import datetime\n",
    "\n",
    "# Load and prepare VIIRS data\n",
    "gdf = gpd.read_file('custom_date_fires.geojson')\n",
    "\n",
    "# Convert VIIRS data to DEM's CRS (EPSG:4269)\n",
    "with rasterio.open('USGS3DEP_30m_33.5_34.5_-119.0_-118.0.tif') as src:\n",
    "    dem_crs = src.crs\n",
    "gdf = gdf.to_crs(dem_crs)\n",
    "\n",
    "# Load and prepare ERA5 data\n",
    "era5_wind = xr.open_dataset('era5_wind_la.nc', engine='netcdf4').rename({'valid_time': 'time'})\n",
    "\n",
    "# Load DEM and calculate slope\n",
    "with rasterio.open('USGS3DEP_30m_33.5_34.5_-119.0_-118.0.tif') as src:\n",
    "    dem = src.read(1)\n",
    "    transform = src.transform\n",
    "    dem_bounds = src.bounds\n",
    "    dem_height, dem_width = dem.shape\n",
    "\n",
    "# Clip VIIRS points to DEM bounds\n",
    "gdf_clipped = gdf.cx[\n",
    "    dem_bounds.left:dem_bounds.right,\n",
    "    dem_bounds.bottom:dem_bounds.top\n",
    "]\n",
    "\n",
    "# Calculate slope using richdem\n",
    "dem_rd = rd.rdarray(dem, no_data=-9999)\n",
    "slope = rd.TerrainAttribute(dem_rd, attrib='slope_degrees')\n",
    "\n",
    "def get_wind_at_point(lat, lon, viirs_time):\n",
    "    \"\"\"Get wind components at specific location and time\"\"\"\n",
    "    # Convert VIIRS time to numpy datetime\n",
    "    era5_time = np.datetime64(viirs_time)\n",
    "    \n",
    "    return era5_wind.sel(\n",
    "        latitude=lat,\n",
    "        longitude=lon,\n",
    "        time=era5_time,\n",
    "        method='nearest'\n",
    "    )\n",
    "\n",
    "# Process features with error handling\n",
    "features = []\n",
    "for _, row in gdf_clipped.iterrows():\n",
    "    try:\n",
    "        # Get wind data\n",
    "        wind = get_wind_at_point(row.geometry.y, row.geometry.x, row['acq_date'])\n",
    "        \n",
    "        # Convert coordinates to DEM grid indices\n",
    "        x, y = row.geometry.x, row.geometry.y\n",
    "        row_idx, col_idx = rowcol(transform, x, y)\n",
    "        \n",
    "        # Check array bounds\n",
    "        if (0 <= row_idx < dem_height) and (0 <= col_idx < dem_width):\n",
    "            elevation = dem[row_idx, col_idx]\n",
    "            slope_value = slope[row_idx, col_idx]\n",
    "        else:\n",
    "            print(f\"Point out of DEM bounds: ({x}, {y})\")\n",
    "            elevation = np.nan\n",
    "            slope_value = np.nan\n",
    "        \n",
    "        features.append({\n",
    "            'latitude': row.geometry.y,\n",
    "            'longitude': row.geometry.x,\n",
    "            'frp': row['frp'],\n",
    "            'u10': wind.u10.item(),\n",
    "            'v10': wind.v10.item(),\n",
    "            'elevation': elevation,\n",
    "            'slope': slope_value,\n",
    "            'confidence': row['confidence']\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row due to error: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "features_df = pd.DataFrame(features)\n",
    "print(\"Successfully processed features:\")\n",
    "print(features_df.head())\n",
    "print(f\"\\nTotal features: {len(features_df)}\")\n",
    "print(f\"NaN values:\\n{features_df.isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4f70626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "import branca.colormap as cm\n",
    "\n",
    "# Create base map centered on LA\n",
    "m = folium.Map(location=[34.05, -118.25], zoom_start=9, tiles='CartoDB dark_matter')\n",
    "\n",
    "# Add Slope Layer (as raster image)\n",
    "slope_colormap = cm.LinearColormap(\n",
    "    ['#2b83ba', '#abdda4', '#ffffbf', '#fdae61', '#d7191c'],\n",
    "    vmin=0, vmax=90,\n",
    "    caption='Slope (degrees)'\n",
    ")\n",
    "\n",
    "# Save slope as temporary GeoTIFF for visualization\n",
    "with rasterio.open('slope.tif', 'w', \n",
    "                   driver='GTiff',\n",
    "                   height=slope.shape[0],\n",
    "                   width=slope.shape[1],\n",
    "                   count=1,\n",
    "                   dtype=slope.dtype,\n",
    "                   crs=dem_crs,\n",
    "                   transform=transform) as dst:\n",
    "    dst.write(slope, 1)\n",
    "\n",
    "# Add slope overlay\n",
    "folium.raster_layers.ImageOverlay(\n",
    "    image='slope.tif',\n",
    "    bounds=[[dem_bounds.bottom, dem_bounds.left], \n",
    "            [dem_bounds.top, dem_bounds.right]],\n",
    "    colormap=slope_colormap,\n",
    "    opacity=0.6,\n",
    "    name='Slope'\n",
    ").add_to(m)\n",
    "\n",
    "# Add VIIRS Fire Points colored by FRP\n",
    "frp_colormap = cm.LinearColormap(\n",
    "    ['yellow', 'orange', 'red'],\n",
    "    vmin=features_df['frp'].min(),\n",
    "    vmax=features_df['frp'].max(),\n",
    "    caption='FRP (MW)'\n",
    ")\n",
    "\n",
    "for idx, row in features_df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=2,\n",
    "        color=frp_colormap(row['frp']),\n",
    "        fill=True,\n",
    "        popup=f\"FRP: {row['frp']} MW<br>Confidence: {row['confidence']}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add Wind Vectors as Arrows\n",
    "for idx, row in features_df.iterrows():\n",
    "    folium.PolyLine(\n",
    "        locations=[\n",
    "            [row['latitude'], row['longitude']],\n",
    "            [row['latitude'] + row['v10']/100,  # Scale for visibility\n",
    "             row['longitude'] + row['u10']/100]\n",
    "        ],\n",
    "        color='#00b3ff',\n",
    "        weight=1.5,\n",
    "        tooltip=f\"Wind: {np.sqrt(row['u10']**2 + row['v10']**2):.1f} m/s\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add layer control and save\n",
    "folium.LayerControl().add_to(m)\n",
    "frp_colormap.add_to(m)\n",
    "m.save('fire_analysis_map.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3b3a99",
   "metadata": {},
   "source": [
    "RUNNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d048a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import richdem as rd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rasterio.transform import rowcol\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79023dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIIRS data columns: ['country_id', 'latitude', 'longitude', 'bright_ti4', 'scan', 'track', 'acq_date', 'acq_time', 'satellite', 'instrument', 'confidence', 'version', 'bright_ti5', 'frp', 'daynight', 'geometry']\n",
      "\n",
      "VIIRS CRS after conversion: GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101004,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4269\"]]\n"
     ]
    }
   ],
   "source": [
    "# Load VIIRS Fire Data\n",
    "gdf = gpd.read_file('custom_date_fires.geojson')\n",
    "print(\"VIIRS data columns:\", gdf.columns.tolist())\n",
    "\n",
    "# Convert to DEM CRS (EPSG:4269)\n",
    "with rasterio.open('USGS3DEP_30m_33.5_34.5_-119.0_-118.0.tif') as src:\n",
    "    dem_crs = src.crs\n",
    "gdf = gdf.to_crs(dem_crs)\n",
    "print(\"\\nVIIRS CRS after conversion:\", gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f1301b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ERA5 variables: ['u10', 'v10']\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A Slope calculation (degrees)\u001b[39m\n",
      "C Horn, B.K.P., 1981. Hill shading and the reflectance map. Proceedings of the IEEE 69, 14–47. doi:10.1109/PROC.1981.11918\u001b[39m\n",
      "\n",
      "\u001b[2Kt Wall-time = 0.274558\u001b[39m======================= ] (99% - 0.0s - 1 threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEM and slope processed\n",
      "\n",
      "Processed features summary:\n",
      "Total valid features: 1731\n",
      "Elevation range: -0.3 - 1717.6 m\n",
      "Slope range: 0.0 - 88.8°\n",
      "\n",
      "Sample features:\n",
      "   latitude  longitude   frp       u10       v10   elevation      slope  \\\n",
      "0  33.81573 -118.23775  1.05  1.259857  3.371613    1.781858  69.389099   \n",
      "1  34.15556 -118.19301  1.56  0.662201  0.849152  434.277283  80.075356   \n",
      "2  34.29366 -118.80275  1.33  0.376068  0.480011  297.056061  56.920059   \n",
      "3  34.33566 -118.51929  1.25  0.539154  0.854034  581.089966  73.065117   \n",
      "4  34.42990 -118.64459  0.86  0.599701 -1.086395  350.062622  75.363266   \n",
      "\n",
      "  confidence  confidence_num  \n",
      "0          n               1  \n",
      "1          n               1  \n",
      "2          n               1  \n",
      "3          n               1  \n",
      "4          n               1  \n"
     ]
    }
   ],
   "source": [
    "# Load ERA5 Wind Data\n",
    "era5_wind = xr.open_dataset('era5_wind_la.nc', engine='netcdf4').rename({'valid_time': 'time'})\n",
    "print(\"\\nERA5 variables:\", list(era5_wind.data_vars))\n",
    "\n",
    "\n",
    "# Load DEM and calculate slope\n",
    "with rasterio.open('USGS3DEP_30m_33.5_34.5_-119.0_-118.0.tif') as src:\n",
    "    dem = src.read(1)\n",
    "    transform = src.transform\n",
    "    dem_height, dem_width = dem.shape\n",
    "    dem_bounds = src.bounds\n",
    "\n",
    "# Calculate slope using richdem\n",
    "dem_rd = rd.rdarray(dem, no_data=-9999)\n",
    "slope = rd.TerrainAttribute(dem_rd, attrib='slope_degrees')\n",
    "print(\"\\nDEM and slope processed\")\n",
    "\n",
    "# Clip VIIRS points to DEM bounds\n",
    "gdf_clipped = gdf.cx[\n",
    "    dem_bounds.left:dem_bounds.right,\n",
    "    dem_bounds.bottom:dem_bounds.top\n",
    "]\n",
    "\n",
    "# Process features with full validation\n",
    "features = []\n",
    "for idx, row in gdf_clipped.iterrows():\n",
    "    try:\n",
    "        # --- Wind Data Extraction ---\n",
    "        # Convert VIIRS time to numpy datetime\n",
    "        era5_time = np.datetime64(row['acq_date'])\n",
    "        \n",
    "        # Get nearest wind data\n",
    "        wind = era5_wind.sel(\n",
    "            time=era5_time,\n",
    "            latitude=row.geometry.y,\n",
    "            longitude=row.geometry.x,\n",
    "            method='nearest'\n",
    "        )\n",
    "        \n",
    "        # --- DEM/Slope Extraction ---\n",
    "        # Convert coordinates to grid indices\n",
    "        x, y = row.geometry.x, row.geometry.y\n",
    "        row_idx, col_idx = rowcol(transform, x, y)\n",
    "        \n",
    "        # Validate indices\n",
    "        valid_row = 0 <= row_idx < dem_height\n",
    "        valid_col = 0 <= col_idx < dem_width\n",
    "        \n",
    "        if valid_row and valid_col:\n",
    "            elevation = dem[row_idx, col_idx]\n",
    "            slope_val = slope[row_idx, col_idx]\n",
    "        else:\n",
    "            elevation = np.nan\n",
    "            slope_val = np.nan\n",
    "        \n",
    "        # --- Feature Collection ---\n",
    "        features.append({\n",
    "            'latitude': row.geometry.y,\n",
    "            'longitude': row.geometry.x,\n",
    "            'frp': row['frp'],\n",
    "            'u10': wind.u10.item(),\n",
    "            'v10': wind.v10.item(),\n",
    "            'elevation': elevation,\n",
    "            'slope': slope_val,\n",
    "            'confidence': row['confidence'].lower()  # Ensure lowercase\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row {idx}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Create DataFrame and clean data\n",
    "features_df = pd.DataFrame(features).dropna(subset=['elevation', 'slope'])\n",
    "\n",
    "# Convert confidence to numerical values (0=low, 1=nominal, 2=high)\n",
    "#features_df['confidence_num'] = pd.factorize(features_df['confidence'])[0]\n",
    "features_df['confidence_num'] = features_df['confidence'].map({'l':0, 'n':1, 'h':2})\n",
    "\n",
    "print(\"\\nProcessed features summary:\")\n",
    "print(f\"Total valid features: {len(features_df)}\")\n",
    "print(f\"Elevation range: {features_df['elevation'].min():.1f} - {features_df['elevation'].max():.1f} m\")\n",
    "print(f\"Slope range: {features_df['slope'].min():.1f} - {features_df['slope'].max():.1f}°\")\n",
    "print(\"\\nSample features:\")\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a4a8522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique confidence values:  ['n' 'l' 'h']\n",
      "[1 0 2]\n",
      "NaN values in confidence_num: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique confidence values: \",gdf_clipped['confidence'].unique())\n",
    "print(features_df['confidence_num'].unique())\n",
    "\n",
    "print(\"NaN values in confidence_num:\", features_df['confidence_num'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4777375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model R² Score: -0.15\n"
     ]
    }
   ],
   "source": [
    "# ## Machine Learning Model\n",
    "# %%\n",
    "# Convert confidence to numerical values\n",
    "#confidence_map = {'l': 0, 'n': 1, 'h': 2}\n",
    "#features_df['confidence_num'] = features_df['confidence'].map(confidence_map)\n",
    "\n",
    "# Prepare data\n",
    "X = features_df[['frp', 'u10', 'v10', 'elevation', 'slope']]\n",
    "y = features_df['confidence_num']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"\\nModel R² Score: {score:.2f}\")\n",
    "\n",
    "features_df['predicted_confidence'] = model.predict(X)\n",
    "features_df['predicted_confidence_rounded'] = features_df['predicted_confidence'].round().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da18f363",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type rdarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m m \u001b[38;5;241m=\u001b[39m folium\u001b[38;5;241m.\u001b[39mMap(location\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m34.05\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m118.25\u001b[39m], zoom_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, tiles\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCartoDB dark_matter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Add slope layer\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m slope_layer \u001b[38;5;241m=\u001b[39m \u001b[43mfolium\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraster_layers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageOverlay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdem_bounds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdem_bounds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdem_bounds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdem_bounds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolormap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Red gradient\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopacity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSlope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_to(m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Add fire points\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m features_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[0;32m~/.pyenv/versions/richdem-env/lib/python3.10/site-packages/folium/raster_layers.py:322\u001b[0m, in \u001b[0;36mImageOverlay.__init__\u001b[0;34m(self, image, bounds, origin, colormap, mercator_project, pixelated, name, overlay, control, show, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mercator_project:\n\u001b[1;32m    318\u001b[0m     image \u001b[38;5;241m=\u001b[39m mercator_transform(\n\u001b[1;32m    319\u001b[0m         image, (bounds[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], bounds[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]), origin\u001b[38;5;241m=\u001b[39morigin\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[43mimage_to_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolormap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolormap\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/richdem-env/lib/python3.10/site-packages/folium/utilities.py:200\u001b[0m, in \u001b[0;36mimage_to_url\u001b[0;34m(image, colormap, origin)\u001b[0m\n\u001b[1;32m    197\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb64encoded\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# Round-trip to ensure a nice formatted json.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     url \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m url\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type rdarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# ## Interactive Visualization\n",
    "# %%\n",
    "# Create base map\n",
    "m = folium.Map(location=[34.05, -118.25], zoom_start=9, tiles='CartoDB dark_matter')\n",
    "\n",
    "# Add slope layer\n",
    "slope_layer = folium.raster_layers.ImageOverlay(\n",
    "    image=slope,\n",
    "    bounds=[[dem_bounds.bottom, dem_bounds.left], \n",
    "            [dem_bounds.top, dem_bounds.right]],\n",
    "    colormap=lambda x: (1, 0, 0, x/90),  # Red gradient\n",
    "    opacity=0.4,\n",
    "    name='Slope'\n",
    ").add_to(m)\n",
    "\n",
    "# Add fire points\n",
    "for idx, row in features_df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=row['frp']/5,\n",
    "        color='#ff4500',\n",
    "        fill=True,\n",
    "        popup=f\"FRP: {row['frp']} MW<br>Slope: {row['slope']:.1f}°\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add wind vectors\n",
    "for idx, row in features_df.iterrows():\n",
    "    folium.PolyLine(\n",
    "        locations=[\n",
    "            [row['latitude'], row['longitude']],\n",
    "            [row['latitude'] + row['v10']/100, \n",
    "             row['longitude'] + row['u10']/100]\n",
    "        ],\n",
    "        color='#00b3ff',\n",
    "        weight=1.5,\n",
    "        tooltip=f\"Wind Speed: {np.sqrt(row['u10']**2 + row['v10']**2):.1f} m/s\"\n",
    "    ).add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m.save('wildfire_analysis.html')\n",
    "print(\"\\nInteractive map saved to wildfire_analysis.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74dd141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n",
      "\n",
      "VIIRS columns: ['country_id', 'latitude', 'longitude', 'bright_ti4', 'scan', 'track', 'acq_date', 'acq_time', 'satellite', 'instrument', 'confidence', 'version', 'bright_ti5', 'frp', 'daynight', 'geometry']\n",
      "\n",
      "Unique confidence values: ['n' 'h' 'l']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "# Check file existence\n",
    "viirs_path = 'custom_date_fires.geojson'\n",
    "print(f\"File exists: {os.path.exists(viirs_path)}\")\n",
    "\n",
    "# Load data with forced lowercase columns\n",
    "gdf = gpd.read_file(viirs_path).rename(columns=lambda x: x.lower())\n",
    "print(\"\\nVIIRS columns:\", gdf.columns.tolist())\n",
    "print(\"\\nUnique confidence values:\", gdf['confidence'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d7da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original VIIRS points: 5140\n",
      "Points within DEM bounds: 1731\n"
     ]
    }
   ],
   "source": [
    "# Convert VIIRS to DEM's CRS\n",
    "with rasterio.open('USGS3DEP_30m_33.5_34.5_-119.0_-118.0.tif') as src:\n",
    "    dem_crs = src.crs\n",
    "    dem_bounds = src.bounds  # (-119.00027, 33.50027, -118.00027, 34.50027)\n",
    "\n",
    "# Spatial filter: Keep only points within DEM bounds\n",
    "gdf_clipped = gdf.cx[\n",
    "    dem_bounds.left:dem_bounds.right,\n",
    "    dem_bounds.bottom:dem_bounds.top\n",
    "]\n",
    "\n",
    "print(f\"Original VIIRS points: {len(gdf)}\")\n",
    "print(f\"Points within DEM bounds: {len(gdf_clipped)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c79a4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clipped VIIRS bounds:\n",
      "[-118.94359   33.77682 -118.01714   34.43543]\n",
      "DEM bounds: BoundingBox(left=-119.00027728978193, bottom=33.50027737376589, right=-118.00027728178192, top=34.500277381765905)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClipped VIIRS bounds:\")\n",
    "print(gdf_clipped.total_bounds)\n",
    "print(\"DEM bounds:\", dem_bounds)\n",
    "\n",
    "# Sample output:\n",
    "# Clipped VIIRS bounds: [-118.999, 33.501, -118.001, 34.499]\n",
    "# DEM bounds: (-119.00027, 33.50027, -118.00027, 34.50027)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b1d5e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactive layered map saved to wildfire_analysis_layers.html\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Normalize slope and save as image\n",
    "slope_np = np.array(slope)\n",
    "slope_norm = (slope_np - np.nanmin(slope_np)) / (np.nanmax(slope_np) - np.nanmin(slope_np))\n",
    "\n",
    "slope_img_path = 'slope_overlay.png'\n",
    "plt.imsave(slope_img_path, slope_norm, cmap='Reds')\n",
    "\n",
    "# Step 2: Create base map\n",
    "m = folium.Map(location=[34.05, -118.25], zoom_start=9, tiles='CartoDB dark_matter')\n",
    "\n",
    "# Step 3: Add slope raster\n",
    "folium.raster_layers.ImageOverlay(\n",
    "    name='Slope',\n",
    "    image=slope_img_path,\n",
    "    bounds=[[dem_bounds.bottom, dem_bounds.left],\n",
    "            [dem_bounds.top, dem_bounds.right]],\n",
    "    opacity=0.4\n",
    ").add_to(m)\n",
    "\n",
    "# Step 4: Define color map\n",
    "confidence_colors = {\n",
    "    0: 'gray',    # low\n",
    "    1: 'orange',  # nominal\n",
    "    2: 'red'      # high\n",
    "}\n",
    "\n",
    "# Step 5: Create FeatureGroups for toggling\n",
    "actual_layer = folium.FeatureGroup(name='Actual Confidence', show=True)\n",
    "predicted_layer = folium.FeatureGroup(name='Predicted Confidence', show=False)\n",
    "\n",
    "# Step 6: Add fire points — actual confidence\n",
    "for idx, row in features_df.iterrows():\n",
    "    actual_conf = row['confidence_num']\n",
    "    color = confidence_colors.get(actual_conf, 'blue')\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=row['frp'] / 5 if row['frp'] > 0 else 2,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Actual Confidence: {actual_conf}<br>FRP: {row['frp']} MW<br>Slope: {row['slope']:.1f}°\"\n",
    "    ).add_to(actual_layer)\n",
    "\n",
    "# Step 7: Add fire points — predicted confidence\n",
    "for idx, row in features_df.iterrows():\n",
    "    predicted_conf = row['predicted_confidence_rounded']\n",
    "    color = confidence_colors.get(predicted_conf, 'blue')\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=row['frp'] / 5 if row['frp'] > 0 else 2,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Predicted Confidence: {predicted_conf}<br>FRP: {row['frp']} MW<br>Slope: {row['slope']:.1f}°\"\n",
    "    ).add_to(predicted_layer)\n",
    "\n",
    "# Step 8: Add wind vectors to the base map\n",
    "for idx, row in features_df.iterrows():\n",
    "    folium.PolyLine(\n",
    "        locations=[\n",
    "            [row['latitude'], row['longitude']],\n",
    "            [row['latitude'] + row['v10']/100, row['longitude'] + row['u10']/100]\n",
    "        ],\n",
    "        color='#00b3ff',\n",
    "        weight=1.5,\n",
    "        tooltip=f\"Wind: {np.sqrt(row['u10']**2 + row['v10']**2):.1f} m/s\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# Step 9: Add the layers to the map\n",
    "actual_layer.add_to(m)\n",
    "predicted_layer.add_to(m)\n",
    "\n",
    "# Step 10: Add layer control\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# Step 11: Save\n",
    "m.save('wildfire_analysis_layers.html')\n",
    "print(\"\\nInteractive layered map saved to wildfire_analysis_layers.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "richdem-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
