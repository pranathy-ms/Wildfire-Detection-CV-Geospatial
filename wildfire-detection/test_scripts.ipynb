{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b77c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FIRES TABLE COLUMNS:\n",
      "==================================================\n",
      "  id (INTEGER)\n",
      "  lat (REAL)\n",
      "  lon (REAL)\n",
      "  date (TEXT)\n",
      "  time (TEXT)\n",
      "  frp (REAL)\n",
      "  brightness (REAL)\n",
      "  confidence (TEXT)\n",
      "  daynight (TEXT)\n",
      "  satellite (TEXT)\n",
      "\n",
      "==================================================\n",
      "SAMPLE FIRE DATA:\n",
      "==================================================\n",
      "Columns: id, lat, lon, date, time, frp, brightness, confidence, daynight, satellite\n",
      "\n",
      "  id: 1\n",
      "  lat: 33.81573\n",
      "  lon: -118.23775\n",
      "  date: 2025-01-07\n",
      "  time: 1007\n",
      "  frp: 1.05\n",
      "  brightness: 297.45\n",
      "  confidence: n\n",
      "  daynight: N\n",
      "  satellite: N20\n",
      "\n",
      "  id: 2\n",
      "  lat: 34.15556\n",
      "  lon: -118.19301\n",
      "  date: 2025-01-07\n",
      "  time: 1007\n",
      "  frp: 1.56\n",
      "  brightness: 309.21\n",
      "  confidence: n\n",
      "  daynight: N\n",
      "  satellite: N20\n",
      "\n",
      "  id: 3\n",
      "  lat: 34.29366\n",
      "  lon: -118.80275\n",
      "  date: 2025-01-07\n",
      "  time: 1007\n",
      "  frp: 1.33\n",
      "  brightness: 310.25\n",
      "  confidence: n\n",
      "  daynight: N\n",
      "  satellite: N20\n",
      "\n",
      "==================================================\n",
      "ALL TABLES:\n",
      "==================================================\n",
      "  ‚úì fires\n",
      "  ‚úì elevation_cache\n",
      "  ‚úì wind_cache\n",
      "  ‚úì predictions\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import config\n",
    "\n",
    "conn = sqlite3.connect(config.DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Check fires table structure\n",
    "print(\"=\" * 50)\n",
    "print(\"FIRES TABLE COLUMNS:\")\n",
    "print(\"=\" * 50)\n",
    "cursor.execute(\"PRAGMA table_info(fires)\")\n",
    "for row in cursor.fetchall():\n",
    "    print(f\"  {row[1]} ({row[2]})\")\n",
    "\n",
    "# Sample some data\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SAMPLE FIRE DATA:\")\n",
    "print(\"=\" * 50)\n",
    "cursor.execute(\"SELECT * FROM fires LIMIT 3\")\n",
    "columns = [desc[0] for desc in cursor.description]\n",
    "print(f\"Columns: {', '.join(columns)}\")\n",
    "print()\n",
    "for row in cursor.fetchall():\n",
    "    for col, val in zip(columns, row):\n",
    "        print(f\"  {col}: {val}\")\n",
    "    print()\n",
    "\n",
    "# Check other tables\n",
    "print(\"=\" * 50)\n",
    "print(\"ALL TABLES:\")\n",
    "print(\"=\" * 50)\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "for table in cursor.fetchall():\n",
    "    print(f\"  ‚úì {table[0]}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646e7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking: /Users/pranathy/Documents/Illinois Tech/Semester 4/Wildfire Detection/Wildfire-Detection-CV-Geospatial/wildfire-detection/data/elevation/elevation_2025-01-07.tif\n",
      "============================================================\n",
      "Format: GTiff\n",
      "CRS: EPSG:4269\n",
      "Bounds: BoundingBox(left=-119.00027728978193, bottom=33.50027737376589, right=-118.00027728178192, top=34.500277381765905)\n",
      "Shape: (3600, 3600)\n",
      "Resolution: (0.00027777778000000425, 0.00027777778000000425)\n",
      "\n",
      "Metadata:\n",
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -999999.0, 'width': 3600, 'height': 3600, 'count': 1, 'crs': CRS.from_wkt('GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101004,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4269\"]]'), 'transform': Affine(0.00027777778000000425, 0.0, -119.00027728978193,\n",
      "       0.0, -0.00027777778000000425, 34.500277381765905)}\n",
      "\n",
      "Tags:\n",
      "{'AREA_OR_POINT': 'Area'}\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from pathlib import Path\n",
    "import config\n",
    "\n",
    "# Find the elevation file\n",
    "elev_dir = config.DATA_DIR / \"elevation\"\n",
    "elev_files = list(elev_dir.glob(\"*.tif\"))\n",
    "\n",
    "if elev_files:\n",
    "    elev_file = elev_files[0]\n",
    "    print(f\"Checking: {elev_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    with rasterio.open(elev_file) as src:\n",
    "        print(f\"Format: {src.driver}\")\n",
    "        print(f\"CRS: {src.crs}\")\n",
    "        print(f\"Bounds: {src.bounds}\")\n",
    "        print(f\"Shape: {src.shape}\")\n",
    "        print(f\"Resolution: {src.res}\")\n",
    "        print(f\"\\nMetadata:\")\n",
    "        print(src.meta)\n",
    "        print(f\"\\nTags:\")\n",
    "        print(src.tags())\n",
    "else:\n",
    "    print(\"No elevation file found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f57d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA VERIFICATION\n",
      "============================================================\n",
      "\n",
      "üî• FIRE DATA:\n",
      "  ‚úì 14 days of data\n",
      "    2025-01-07: 67 detections\n",
      "    2025-01-08: 885 detections\n",
      "    2025-01-09: 396 detections\n",
      "    2025-01-10: 124 detections\n",
      "    2025-01-11: 243 detections\n",
      "    2025-01-12: 16 detections\n",
      "    2025-01-13: 10 detections\n",
      "    2025-01-14: 10 detections\n",
      "    2025-01-15: 8 detections\n",
      "    2025-01-16: 10 detections\n",
      "    2025-01-17: 3 detections\n",
      "    2025-01-18: 3 detections\n",
      "    2025-01-19: 14 detections\n",
      "    2025-01-20: 1 detections\n",
      "  Total: 1790 fire detections\n",
      "\n",
      "‚õ∞Ô∏è  ELEVATION DATA:\n",
      "  ‚úì File exists: /Users/pranathy/Documents/Illinois Tech/Semester 4/Wildfire Detection/Wildfire-Detection-CV-Geospatial/wildfire-detection/data/elevation/elevation_LA.tif\n",
      "    Size: 25.37 MB\n",
      "    Downloaded: 2025-12-28T23:45:54.906013\n",
      "    Shape: [3600, 3600]\n",
      "    Resolution: [0.00027777778000000425, 0.00027777778000000425]\n",
      "\n",
      "üå¨Ô∏è  WIND DATA:\n",
      "  ‚úì 14 days of data\n",
      "    2025-01-07: ‚úì (0.03 MB)\n",
      "    2025-01-08: ‚úì (0.03 MB)\n",
      "    2025-01-09: ‚úì (0.03 MB)\n",
      "    2025-01-10: ‚úì (0.03 MB)\n",
      "    2025-01-11: ‚úì (0.03 MB)\n",
      "    2025-01-12: ‚úì (0.03 MB)\n",
      "    2025-01-13: ‚úì (0.03 MB)\n",
      "    2025-01-14: ‚úì (0.03 MB)\n",
      "    2025-01-15: ‚úì (0.03 MB)\n",
      "    2025-01-16: ‚úì (0.03 MB)\n",
      "    2025-01-17: ‚úì (0.03 MB)\n",
      "    2025-01-18: ‚úì (0.03 MB)\n",
      "    2025-01-19: ‚úì (0.03 MB)\n",
      "    2025-01-20: ‚úì (0.03 MB)\n",
      "\n",
      "============================================================\n",
      "SUMMARY:\n",
      "============================================================\n",
      "üî• Fires: ‚úì\n",
      "‚õ∞Ô∏è  Elevation: ‚úì\n",
      "üå¨Ô∏è  Wind: ‚úì\n",
      "\n",
      "‚úÖ ALL DATA READY FOR PROCESSING\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import config\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def verify_all_data():\n",
    "    \"\"\"Verify all downloaded data is complete and accessible\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATA VERIFICATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    conn = sqlite3.connect(config.DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # 1. Check fires\n",
    "    print(\"\\nüî• FIRE DATA:\")\n",
    "    cursor.execute(\"SELECT date, COUNT(*) FROM fires GROUP BY date ORDER BY date\")\n",
    "    fire_dates = cursor.fetchall()\n",
    "    \n",
    "    if fire_dates:\n",
    "        print(f\"  ‚úì {len(fire_dates)} days of data\")\n",
    "        for date, count in fire_dates:\n",
    "            print(f\"    {date}: {count} detections\")\n",
    "        total_fires = sum(count for _, count in fire_dates)\n",
    "        print(f\"  Total: {total_fires} fire detections\")\n",
    "    else:\n",
    "        print(\"  ‚úó No fire data found\")\n",
    "    \n",
    "    # 2. Check elevation\n",
    "    print(\"\\n‚õ∞Ô∏è  ELEVATION DATA:\")\n",
    "    cursor.execute(\"SELECT file_path, downloaded_at, metadata FROM elevation_cache\")\n",
    "    elev = cursor.fetchone()\n",
    "    \n",
    "    if elev:\n",
    "        file_path, downloaded_at, metadata = elev\n",
    "        if Path(file_path).exists():\n",
    "            file_size = Path(file_path).stat().st_size / (1024 * 1024)  # MB\n",
    "            print(f\"  ‚úì File exists: {file_path}\")\n",
    "            print(f\"    Size: {file_size:.2f} MB\")\n",
    "            print(f\"    Downloaded: {downloaded_at}\")\n",
    "            \n",
    "            if metadata:\n",
    "                meta = json.loads(metadata)\n",
    "                print(f\"    Shape: {meta.get('shape', 'N/A')}\")\n",
    "                print(f\"    Resolution: {meta.get('resolution', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"  ‚úó File missing: {file_path}\")\n",
    "    else:\n",
    "        print(\"  ‚úó No elevation data in database\")\n",
    "    \n",
    "    # 3. Check wind\n",
    "    print(\"\\nüå¨Ô∏è  WIND DATA:\")\n",
    "    cursor.execute(\"SELECT date, file_path FROM wind_cache ORDER BY date\")\n",
    "    wind_data = cursor.fetchall()\n",
    "    \n",
    "    if wind_data:\n",
    "        print(f\"  ‚úì {len(wind_data)} days of data\")\n",
    "        missing = []\n",
    "        for date, file_path in wind_data:\n",
    "            if Path(file_path).exists():\n",
    "                file_size = Path(file_path).stat().st_size / (1024 * 1024)\n",
    "                print(f\"    {date}: ‚úì ({file_size:.2f} MB)\")\n",
    "            else:\n",
    "                print(f\"    {date}: ‚úó FILE MISSING\")\n",
    "                missing.append(date)\n",
    "        \n",
    "        if missing:\n",
    "            print(f\"\\n  ‚ö†Ô∏è  {len(missing)} wind files missing!\")\n",
    "    else:\n",
    "        print(\"  ‚úó No wind data in database\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    # 4. Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    has_fires = len(fire_dates) > 0 if fire_dates else False\n",
    "    has_elevation = elev and Path(elev[0]).exists()\n",
    "    has_wind = len(wind_data) > 0 if wind_data else False\n",
    "    all_wind_exist = all(Path(fp).exists() for _, fp in wind_data) if wind_data else False\n",
    "    \n",
    "    print(f\"üî• Fires: {'‚úì' if has_fires else '‚úó'}\")\n",
    "    print(f\"‚õ∞Ô∏è  Elevation: {'‚úì' if has_elevation else '‚úó'}\")\n",
    "    print(f\"üå¨Ô∏è  Wind: {'‚úì' if has_wind and all_wind_exist else '‚úó'}\")\n",
    "    \n",
    "    if has_fires and has_elevation and has_wind and all_wind_exist:\n",
    "        print(\"\\n‚úÖ ALL DATA READY FOR PROCESSING\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  SOME DATA MISSING - CHECK ABOVE\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    verify_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f62ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LABEL VERIFICATION\n",
      "============================================================\n",
      "\n",
      "1. SPATIAL DISTRIBUTION:\n",
      "   Unique locations with spread=1: 68\n",
      "   Unique locations with spread=0: 363\n",
      "\n",
      "2. TEMPORAL DISTRIBUTION:\n",
      "            spread_yes  total  spread_rate\n",
      "date                                      \n",
      "2025-01-07          21     56     0.375000\n",
      "2025-01-08          81    331     0.244713\n",
      "2025-01-09          57    326     0.174847\n",
      "2025-01-10          29    266     0.109023\n",
      "2025-01-11           3    150     0.020000\n",
      "2025-01-12           3     80     0.037500\n",
      "2025-01-13           4     62     0.064516\n",
      "2025-01-14           5     59     0.084746\n",
      "2025-01-15           3     52     0.057692\n",
      "2025-01-16           1     40     0.025000\n",
      "2025-01-17           2     24     0.083333\n",
      "2025-01-18           3     24     0.125000\n",
      "\n",
      "3. SPREAD RATE BY DATE:\n",
      "   2025-01-07: 37.50% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-01-08: 24.47% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-01-09: 17.48% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-01-10: 10.90% ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-01-11: 2.00% ‚ñà\n",
      "   2025-01-12: 3.75% ‚ñà\n",
      "   2025-01-13: 6.45% ‚ñà‚ñà‚ñà\n",
      "   2025-01-14: 8.47% ‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-01-15: 5.77% ‚ñà‚ñà\n",
      "   2025-01-16: 2.50% ‚ñà\n",
      "   2025-01-17: 8.33% ‚ñà‚ñà‚ñà‚ñà\n",
      "   2025-01-18: 12.50% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "4. SAMPLE SPREAD=1 EXAMPLES:\n",
      "\n",
      "   Example 0:\n",
      "   Location: (34.0700, -118.5600)\n",
      "   Date: 2025-01-07\n",
      "   Center cell burning: 0.0\n",
      "\n",
      "   Example 1:\n",
      "   Location: (34.0800, -118.5600)\n",
      "   Date: 2025-01-07\n",
      "   Center cell burning: 0.0\n",
      "\n",
      "   Example 2:\n",
      "   Location: (34.0800, -118.5500)\n",
      "   Date: 2025-01-07\n",
      "   Center cell burning: 0.0\n",
      "\n",
      "   Example 3:\n",
      "   Location: (34.0800, -118.5400)\n",
      "   Date: 2025-01-07\n",
      "   Center cell burning: 0.0\n",
      "\n",
      "   Example 4:\n",
      "   Location: (34.0600, -118.5200)\n",
      "   Date: 2025-01-07\n",
      "   Center cell burning: 0.0\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import config\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_pickle(config.DATA_DIR / \"processed\" / \"training_dataset.pkl\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LABEL VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Check spatial distribution\n",
    "print(\"\\n1. SPATIAL DISTRIBUTION:\")\n",
    "print(f\"   Unique locations with spread=1: {df[df['spread']==1][['target_lat', 'target_lon']].drop_duplicates().shape[0]}\")\n",
    "print(f\"   Unique locations with spread=0: {df[df['spread']==0][['target_lat', 'target_lon']].drop_duplicates().shape[0]}\")\n",
    "\n",
    "# 2. Check temporal distribution\n",
    "print(\"\\n2. TEMPORAL DISTRIBUTION:\")\n",
    "spread_by_date = df.groupby('date')['spread'].agg(['sum', 'count', 'mean'])\n",
    "spread_by_date.columns = ['spread_yes', 'total', 'spread_rate']\n",
    "print(spread_by_date)\n",
    "\n",
    "# 3. Check for suspicious patterns\n",
    "print(\"\\n3. SPREAD RATE BY DATE:\")\n",
    "for date, rate in zip(spread_by_date.index, spread_by_date['spread_rate']):\n",
    "    bar = \"‚ñà\" * int(rate * 50)\n",
    "    print(f\"   {date}: {rate:.2%} {bar}\")\n",
    "\n",
    "# 4. Sample some spread=1 examples\n",
    "print(\"\\n4. SAMPLE SPREAD=1 EXAMPLES:\")\n",
    "spread_examples = df[df['spread'] == 1].head(5)\n",
    "for idx, row in spread_examples.iterrows():\n",
    "    print(f\"\\n   Example {idx}:\")\n",
    "    print(f\"   Location: ({row['target_lat']:.4f}, {row['target_lon']:.4f})\")\n",
    "    print(f\"   Date: {row['date']}\")\n",
    "    # Check if center cell of patch has is_burning=1 (would be suspicious)\n",
    "    patch = row['patch_features']\n",
    "    center_idx = (5 * 5 // 2) * 7  # Center cell, 7 features per cell\n",
    "    is_burning = patch[center_idx + 6]  # 7th feature is is_burning\n",
    "    print(f\"   Center cell burning: {is_burning}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37eaa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TERRAIN DATA DEBUGGING\n",
      "============================================================\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A Slope calculation (degrees)\u001b[39m\n",
      "C Horn, B.K.P., 1981. Hill shading and the reflectance map. Proceedings of the IEEE 69, 14‚Äì47. doi:10.1109/PROC.1981.11918\u001b[39m\n",
      "\n",
      "\u001b[2Kt Wall-time = 0.23043\u001b[39m======================== ] (99% - 0.0s - 1 threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEM Stats:\n",
      "  Shape: (3600, 3600)\n",
      "  Min elevation: -5.0m\n",
      "  Max elevation: 2167.9m\n",
      "  Invalid cells (< 0): 108140\n",
      "\n",
      "Slope Stats:\n",
      "  Min slope: 0.00¬∞\n",
      "  Max slope: 89.21¬∞\n",
      "  Zero slope cells: 5115770\n",
      "  Invalid slope (==0): 39.5%\n",
      "\n",
      "Grid Coverage Check:\n",
      "  Grid cells: 100 x 100 = 10000\n",
      "  Valid cells: 5930\n",
      "  Out of DEM bounds: 100\n",
      "  Invalid terrain (elev<0 or slope=0): 3970\n",
      "  Coverage: 59.3%\n",
      "\n",
      "Checking why cells are invalid:\n",
      "  Sample invalid cells:\n",
      "    (33.5100, -119.0000): elev=0.0, slope=0.00\n",
      "    (33.5100, -118.9900): elev=0.0, slope=0.00\n",
      "    (33.5100, -118.9800): elev=0.0, slope=0.00\n",
      "    (33.5100, -118.9700): elev=0.0, slope=0.00\n",
      "    (33.5100, -118.9600): elev=0.0, slope=0.00\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import config\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import richdem as rd\n",
    "from rasterio.transform import rowcol\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TERRAIN DATA DEBUGGING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load elevation\n",
    "conn = sqlite3.connect(config.DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT file_path FROM elevation_cache LIMIT 1\")\n",
    "dem_file = cursor.fetchone()[0]\n",
    "conn.close()\n",
    "\n",
    "with rasterio.open(dem_file) as src:\n",
    "    dem = src.read(1)\n",
    "    transform = src.transform\n",
    "\n",
    "dem_rd = rd.rdarray(dem, no_data=-999999)\n",
    "slope = rd.TerrainAttribute(dem_rd, attrib='slope_degrees')\n",
    "\n",
    "print(f\"\\nDEM Stats:\")\n",
    "print(f\"  Shape: {dem.shape}\")\n",
    "print(f\"  Min elevation: {dem[dem > -999999].min():.1f}m\")\n",
    "print(f\"  Max elevation: {dem[dem > -999999].max():.1f}m\")\n",
    "print(f\"  Invalid cells (< 0): {(dem < 0).sum()}\")\n",
    "\n",
    "print(f\"\\nSlope Stats:\")\n",
    "print(f\"  Min slope: {slope[slope > 0].min():.2f}¬∞\")\n",
    "print(f\"  Max slope: {slope[slope > 0].max():.2f}¬∞\")\n",
    "print(f\"  Zero slope cells: {(slope == 0).sum()}\")\n",
    "print(f\"  Invalid slope (==0): {(slope == 0).sum() / slope.size * 100:.1f}%\")\n",
    "\n",
    "# Check grid coverage\n",
    "deg_per_km = 0.01\n",
    "grid_step = config.GRID_SIZE_KM * deg_per_km\n",
    "lats = np.arange(config.LAT_MIN, config.LAT_MAX, grid_step)\n",
    "lons = np.arange(config.LON_MIN, config.LON_MAX, grid_step)\n",
    "\n",
    "print(f\"\\nGrid Coverage Check:\")\n",
    "print(f\"  Grid cells: {len(lats)} x {len(lons)} = {len(lats) * len(lons)}\")\n",
    "\n",
    "valid_count = 0\n",
    "invalid_terrain = 0\n",
    "out_of_bounds = 0\n",
    "\n",
    "for i, lat in enumerate(lats):\n",
    "    for j, lon in enumerate(lons):\n",
    "        row_idx, col_idx = rowcol(transform, lon, lat)\n",
    "        \n",
    "        if not (0 <= row_idx < dem.shape[0] and 0 <= col_idx < dem.shape[1]):\n",
    "            out_of_bounds += 1\n",
    "            continue\n",
    "        \n",
    "        elevation = float(dem[row_idx, col_idx])\n",
    "        slope_val = float(slope[row_idx, col_idx])\n",
    "        \n",
    "        if elevation < 0 or slope_val == 0:\n",
    "            invalid_terrain += 1\n",
    "            continue\n",
    "        \n",
    "        valid_count += 1\n",
    "\n",
    "print(f\"  Valid cells: {valid_count}\")\n",
    "print(f\"  Out of DEM bounds: {out_of_bounds}\")\n",
    "print(f\"  Invalid terrain (elev<0 or slope=0): {invalid_terrain}\")\n",
    "print(f\"  Coverage: {valid_count / (len(lats) * len(lons)) * 100:.1f}%\")\n",
    "\n",
    "# Check specific problem areas\n",
    "print(f\"\\nChecking why cells are invalid:\")\n",
    "sample_invalid = []\n",
    "for i, lat in enumerate(lats[:10]):  # First 10 rows\n",
    "    for j, lon in enumerate(lons[:10]):\n",
    "        row_idx, col_idx = rowcol(transform, lon, lat)\n",
    "        if 0 <= row_idx < dem.shape[0] and 0 <= col_idx < dem.shape[1]:\n",
    "            elevation = float(dem[row_idx, col_idx])\n",
    "            slope_val = float(slope[row_idx, col_idx])\n",
    "            if elevation < 0 or slope_val == 0:\n",
    "                sample_invalid.append({\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'elevation': elevation,\n",
    "                    'slope': slope_val\n",
    "                })\n",
    "\n",
    "if sample_invalid:\n",
    "    print(f\"  Sample invalid cells:\")\n",
    "    for cell in sample_invalid[:5]:\n",
    "        print(f\"    ({cell['lat']:.4f}, {cell['lon']:.4f}): elev={cell['elevation']:.1f}, slope={cell['slope']:.2f}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa28bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE SANITY CHECK\n",
      "============================================================\n",
      "\n",
      "Sample patch (175 features = 25 cells √ó 7):\n",
      "Total features: 175\n",
      "\n",
      "Cell 0 (corner):\n",
      "  Elevation: 36.6m\n",
      "  Slope: 83.81¬∞\n",
      "  Wind speed: 1.70 m/s\n",
      "  Wind alignment: -0.58\n",
      "  Distance to fire: 0.84 km\n",
      "  Fire intensity: 11.6 MW\n",
      "  Is burning: 0.0\n",
      "\n",
      "Cell 12 (center):\n",
      "  Elevation: 183.7m\n",
      "  Slope: 37.99¬∞\n",
      "  Wind speed: 1.70 m/s\n",
      "  Wind alignment: -0.24\n",
      "  Distance to fire: 1.10 km\n",
      "  Fire intensity: 12.5 MW\n",
      "  Is burning: 0.0\n",
      "\n",
      "Cell 24 (corner):\n",
      "  Elevation: 513.8m\n",
      "  Slope: 71.94¬∞\n",
      "  Wind speed: 1.70 m/s\n",
      "  Wind alignment: -0.96\n",
      "  Distance to fire: 1.64 km\n",
      "  Fire intensity: 65.7 MW\n",
      "  Is burning: 0.0\n",
      "\n",
      "============================================================\n",
      "DATA QUALITY CHECK\n",
      "============================================================\n",
      "Total feature values: 264250\n",
      "NaN values: 0\n",
      "Infinite values: 0\n",
      "Min value: -1.00\n",
      "Max value: 1707.76\n",
      "\n",
      "============================================================\n",
      "FEATURE RANGES (across all patches)\n",
      "============================================================\n",
      "elevation   : min=    0.00, max= 1707.76, mean=  417.54\n",
      "slope       : min=    0.00, max=   88.26, mean=   66.93\n",
      "wind_speed  : min=    0.58, max=    2.55, mean=    1.69\n",
      "wind_align  : min=   -1.00, max=    1.00, mean=    0.10\n",
      "distance    : min=    0.01, max=    6.12, mean=    1.89\n",
      "frp         : min=    0.00, max=  478.20, mean=   11.37\n",
      "is_burning  : min=    0.00, max=    1.00, mean=    0.20\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config\n",
    "\n",
    "df = pd.read_pickle(config.DATA_DIR / \"processed\" / \"training_dataset.pkl\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE SANITY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample one patch\n",
    "sample = df.iloc[0]['patch_features']\n",
    "print(f\"\\nSample patch (175 features = 25 cells √ó 7):\")\n",
    "print(f\"Total features: {len(sample)}\")\n",
    "\n",
    "# Check each cell in 5x5\n",
    "for cell_idx in range(25):\n",
    "    start = cell_idx * 7\n",
    "    features = sample[start:start+7]\n",
    "    \n",
    "    elev, slope, wind_speed, wind_align, dist, frp, is_burn = features\n",
    "    \n",
    "    if cell_idx == 0 or cell_idx == 12 or cell_idx == 24:  # Corners and center\n",
    "        print(f\"\\nCell {cell_idx} ({'center' if cell_idx==12 else 'corner'}):\")\n",
    "        print(f\"  Elevation: {elev:.1f}m\")\n",
    "        print(f\"  Slope: {slope:.2f}¬∞\")\n",
    "        print(f\"  Wind speed: {wind_speed:.2f} m/s\")\n",
    "        print(f\"  Wind alignment: {wind_align:.2f}\")\n",
    "        print(f\"  Distance to fire: {dist:.2f} km\")\n",
    "        print(f\"  Fire intensity: {frp:.1f} MW\")\n",
    "        print(f\"  Is burning: {is_burn}\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_features = np.array([f for patches in df['patch_features'] for f in patches])\n",
    "print(f\"Total feature values: {len(all_features)}\")\n",
    "print(f\"NaN values: {np.isnan(all_features).sum()}\")\n",
    "print(f\"Infinite values: {np.isinf(all_features).sum()}\")\n",
    "print(f\"Min value: {np.min(all_features):.2f}\")\n",
    "print(f\"Max value: {np.max(all_features):.2f}\")\n",
    "\n",
    "# Feature ranges\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE RANGES (across all patches)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "features_by_type = {\n",
    "    'elevation': [],\n",
    "    'slope': [],\n",
    "    'wind_speed': [],\n",
    "    'wind_align': [],\n",
    "    'distance': [],\n",
    "    'frp': [],\n",
    "    'is_burning': []\n",
    "}\n",
    "\n",
    "for patches in df['patch_features']:\n",
    "    for cell_idx in range(25):\n",
    "        start = cell_idx * 7\n",
    "        features = patches[start:start+7]\n",
    "        \n",
    "        features_by_type['elevation'].append(features[0])\n",
    "        features_by_type['slope'].append(features[1])\n",
    "        features_by_type['wind_speed'].append(features[2])\n",
    "        features_by_type['wind_align'].append(features[3])\n",
    "        features_by_type['distance'].append(features[4])\n",
    "        features_by_type['frp'].append(features[5])\n",
    "        features_by_type['is_burning'].append(features[6])\n",
    "\n",
    "for name, values in features_by_type.items():\n",
    "    values = np.array(values)\n",
    "    print(f\"{name:12s}: min={values.min():8.2f}, max={values.max():8.2f}, mean={values.mean():8.2f}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "richdem-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
